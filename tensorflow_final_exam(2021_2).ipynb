{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "텐활기기말고사(2021_2학기).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5DQeTMWiLgDQn7opAP9T7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongchuu/TensorflowTeam5/blob/main/tensorflow_final_exam(2021_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O5KdCpgQE-s"
      },
      "source": [
        "## 1. Kaggle 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngVYCt8JOSu5",
        "outputId": "15856aae-888c-4cda-b43d-37559508290c"
      },
      "source": [
        "## 1. Kaggle 데이터셋 로드\n",
        "## https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/ \n",
        "\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets download alxmamaev/flowers-recognition\n",
        "\n",
        "! unzip flowers-recognition.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzwKugLvMtE2",
        "outputId": "af27a1e9-cd2f-475e-d714-b667b67f88c7"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juDlu5ZgMJLY",
        "outputId": "2e42d6dd-d6c1-4c18-ec7d-9a59d37ea5b3"
      },
      "source": [
        "#### 튜토리얼 방식의 이미지 로드\n",
        "\n",
        "import pathlib\n",
        "import glob\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='flower_photos', \n",
        "                                   untar=True)\n",
        "print(data_dir)\n",
        "images = glob.glob(os.path.join(data_dir, '*', '*'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/flower_photos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dis99w_QQAvR"
      },
      "source": [
        "## 2. 데이터 셋 생성 (train/ val)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3DjOntbNpB2"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "img_height = 256\n",
        "img_width = 256"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNA7pgjKNxYF",
        "outputId": "a933d94e-8732-4f47-b463-0d83270a4602"
      },
      "source": [
        "## tf.keras.preprocessing.image_dataset_from_directory\n",
        "## https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory \n",
        "## return tf.data.Dataset\n",
        "\n",
        "## main_directory/\n",
        "## ...class_a/\n",
        "## ......a_image_1.jpg\n",
        "## ......a_image_2.jpg\n",
        "## ...class_b/\n",
        "## ......b_image_1.jpg\n",
        "## ......b_image_2.jpg\n",
        "\n",
        "## Then calling image_dataset_from_directory(main_directory, labels='inferred') will return a tf.data.Dataset \n",
        "## that yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b).\n",
        "\n",
        "data_path = '/content/flowers'\n",
        "\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_path,\n",
        "  validation_split=0.2, # validation_split\tOptional float between 0 and 1, fraction of data to reserve for validation.\n",
        "  subset=\"training\", # subset\tOne of \"training\" or \"validation\". Only used if validation_split is set.\n",
        "  seed=10,\n",
        "  # image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 files belonging to 5 classes.\n",
            "Using 3454 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNc7mZWoPoFX",
        "outputId": "227b74dd-7555-41db-d8bf-e4da27b8dc60"
      },
      "source": [
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_path,\n",
        "  validation_split=0.2, # validation_split\tOptional float between 0 and 1, fraction of data to reserve for validation.\n",
        "  subset=\"validation\", # subset\tOne of \"training\" or \"validation\". Only used if validation_split is set.\n",
        "  seed=10,\n",
        "  # image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 files belonging to 5 classes.\n",
            "Using 863 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvZkio20QPCm",
        "outputId": "88e39036-c099-48fd-bd68-d0369c578614"
      },
      "source": [
        "## class 이름 확인\n",
        "class_names = train_dataset.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLMbzvcaSV3N"
      },
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-yet6dAVZT0"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1QHTmEgWbY7",
        "outputId": "3178925b-4906-4d07-fba5-66728490a0e4"
      },
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "normalized_ds = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "print(normalized_ds)\n",
        "# image_batch, labels_batch = next(iter(normalized_ds))\n",
        "# first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "# print(np.min(first_image), np.max(first_image)) "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MapDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>\n"
          ]
        }
      ]
    }
  ]
}